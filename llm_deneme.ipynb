{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olL8lNsbMWcP",
    "outputId": "cd927ec9-690f-40af-f020-0a0cbc672d3b"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708,
     "referenced_widgets": [
      "edf7186369224201b6ba213897cf1634",
      "56edd8afbd1e475c86caf4c7fdf87c82",
      "5e6c4ceb6b9d41b7b1ba5a7dee651704",
      "9d8a76ad492c4b159d3d9eafc5ce6878",
      "3782874859da49759cad518e95351b7f",
      "c5591b30740349fdbe998d03e80094a6",
      "fb84781ac3a24546813afb9c7a9b277e",
      "ccb682c73d314a098d38169c855f763a",
      "02f192251a2e4497aaea0cdee0d9997b",
      "100968ad8ba246058561f6463226199f",
      "83798ebec37a4d4da297f60bd21fe430",
      "319f0ae07bc445afa840cac7ffb3321a",
      "162f4df968964634a87e389fe65007af",
      "cdf577b23a694acf9e5aa0447c735e4e",
      "c1c5dba582cd4281b220031a54bd4587",
      "34f7a399b71c45fa94d1cffa90ebfae3",
      "4030bc9ea9e34035af069629182b4d39",
      "96ae022e32e24d3a83433c31d8a73431",
      "070900f1af504c0ab10ef360690eba04",
      "e176ac9a8c574d1e86af43519d350e6d",
      "e2aa8d757b9c4e07aa1eee8dbcadc4ec",
      "7a672c2a7d574132b423330bbe3236c2",
      "a954105cdce646438c7c0a4056a4d019",
      "82d21082eca24d54a5512ee775a53960",
      "7856735677864919a829c98e0c58cefe",
      "7d0b5b0cb9574708869d65eb28dc945b",
      "28bff204a119494ab6d0fb473b93a181",
      "4c35450ba7964540b6694121e441c3f6",
      "155536ce148b4bdfba05848102b5c030",
      "18fdef822701453cbc36adac11bd86ea",
      "76bfe7c458e842a3884ddb423204907c",
      "80efdd6b2b764789ad118dcde203ef49",
      "db77f0499c6d4541ac57e4afb1871cf1",
      "a16fdf1f25f3495eb87e50eda14fe828",
      "efae23848e7c4803a6e51473d6234ae3",
      "4368ad2e519e44c09b2ada0262389858",
      "1b1c967a8d2849ad9308679462800d6c",
      "2b6c8f96ba2d4d87a44b2828f3fb80cd",
      "f1b945fab4f84a38b96f9407d0e736af",
      "c3c3c286b5394cd8a1cbb7272cd34f24",
      "c94e857b346e4041b043e3935f1cbac6",
      "d8496972f8194cd38929cc36df132a95",
      "94ddbff420fe4abda0f5b6fde83d97f7",
      "bf5d63b65e6146208c79e3a5e197ac1e",
      "b993e43f5b324b8d844afcf3a9211bd3",
      "090caaab41c646449d7e8b13a51e68da",
      "941592f9f4a54b9b9d5837bb119160cd",
      "22c6d1f5e4f740c3906389e700c0f134",
      "078877ea793942a1bfc87e4b14a2cc96",
      "d2da70884e964f33be54e57a632a67b9",
      "507f52091678438fa464287a786a6683",
      "9b1662f4350240ec8279a5fed634b5ea",
      "cf8164bf81a3473b9d476587d5b4bb5a",
      "dda2cd0f40c34a26869ba5dcdcb6fa03",
      "8b78cb9333c447cba19b060d82307b5b",
      "bf5eec400c2244879dc7209ba8ea6371",
      "1f1a4f9b340e4115b5a6328f135b1ec7",
      "5f636d8a86e247018188601d94bcd6b4",
      "8f733f616ce24f9f826467e0fc29a164",
      "65189d1a9690479a80edae1c4c1174a3",
      "e744789eab144fef98d1a52d8688a29b",
      "a757f6ef8cfa4202a73a16b87938ada2",
      "e0853aff24b64d89b50e748541f642d7",
      "9860d1ea5e6d40149c768ad9c4062f43",
      "8ccbefbd42ce4f3cb82f606ee71a8c6b",
      "e6fe6cc9b84d41eb8bde7e53c40b7ebf",
      "1edc7836b64342819fcd513d7d9d8df8",
      "7e32a821a1a4404c8edfa0924eaf795a",
      "157a0175d5274a8d9ad2e4de72d87b8a",
      "b11dc3879ca44455aec1e10109e75050",
      "73fda620d71948399280f8f15e6179a0",
      "1f1eb02dc6ab477a9c45536d30b61f55",
      "89c49a7026a345e8ba232501e8e97bfd",
      "e42ea5b489244782aed4df711adcc09f",
      "f7bdbea1dd13489a9ba648d71a0bfbed",
      "33d6e0da3acc43b5bd329c5b49662c4d",
      "25332c2e292a4c09a671b003fb06a198",
      "aeb4970811ae4b9da0f2ac23432ac35b",
      "4f7199a89b3e426bbaeabac312fe9a3b",
      "8dca82b5cecd416e839bc957a1023ff1",
      "a2b887194fe0407c838397fd42f18526",
      "e19e546f2f9f48f79df45ed41a98a1df",
      "81b39757ae71406e96214c73027f82d0",
      "7dd85e9fcd684cea8a7500c1430f6c27",
      "b81c5d71d42e4678b77645f056313cc6",
      "0a4f72edcfd44bb4b877096f6480148b",
      "700e73722c6340cc86460061799d2465",
      "3e132eff86584d2397e8c75e744f6354",
      "1684c6c2f3584d73ba8abc9361e50672",
      "7309166043174658acafc9624cb45dd8",
      "c436227f48b443beab3c0a8996ade324",
      "ca2270925f244aa198752d2aebd0e352",
      "b63eab2335964d3d9757af97a4f997b8",
      "be4193db409a470aadb44e3712afec4d",
      "240a5e6c31c74226b1f22e574727ac5e",
      "ce336047de314416bd6e3040a754051f",
      "812d4c604a5a41b59c38f6ff2d344ab2",
      "b9a8703b67e34817918d253847ee955e",
      "f69c1631bddf4d57bc1487bd782ddde2",
      "185a247a3dca413b829a4f5a97a49abd",
      "838b772b007542feb848154f0e6bbb17",
      "ca67e59936a242adbe7ea49a0b90e09b",
      "ea025e93af364dce8310b0099ac7a05c",
      "f6c206f3430446f4a5edd4e63c9ccddd",
      "c0a8f4a673cb4948be39523521865da1",
      "b1cca1b3562b44b2b54b3d3e648eb772",
      "9a9abddca67a4f89bdc4490855324857",
      "a13f87b4e1b947649db6ae3a671900ed",
      "d122de79ddcb47c08d2421b8a59142e8",
      "104d5af3718248c695ef62c8523ed897",
      "c9967e401c0e4b83b88ea40e91572353",
      "716516d07ab944819aaee258e109c4b7",
      "bb21d1fa7dbc4eacba8b300d1a5de33c",
      "b05a5fb819874eff9448dcd93ac425f7",
      "0243e65ab7d948818dfdbdbed038d77e",
      "a0d1298fb5ac4e82a56c974b3c05a2d9",
      "8b23378f031c43f0a18b7d0899b49f2a",
      "d34373a5c12341c4b36bc1abbe679fc5",
      "86b1c8a917724e5b90576f94fd0a9553",
      "b0511a1af8f645988fce1bf5fbb1c70d",
      "1a08ca4c00ff489dabc82292283b545c",
      "0b86834ee32d4d62ab2c3a5b6ef84a84",
      "6f0ba3b0a88c4652955691b983824dfc",
      "151627afe30e4cb8933436c033e45abb",
      "0f3705fa4287446eb44596a4d3562c2f",
      "cd01bf17b119409fb8233f77615aaf98",
      "ca0173d98ef543f5a5b413b2ee1f6227",
      "0436a3033c7d48439bdaf79aa4fb7030",
      "21d4e3ca06974e8ab80909b955eb2151",
      "a90d6e6e402f441a99a8e6870697e0b4",
      "033ede949bba49288df5a8def5c8fced",
      "570ea038c9a14bceab1f42833b22b07d",
      "2d5a6629722540c78d8441e0f16dc8ac",
      "4f54d4ef48e041209735208c67fc6216",
      "a51dff5c772e464788a64aa83a8fafaa",
      "b92b16a1f19c48b28db884985b98f748",
      "73060e94541b46688f98dc29a96d8f11",
      "c6f4202a028448e2813cc99563bf7eae",
      "b89e66c4b4e5455bb0b3679ba3e8538c",
      "1a87b382da6f46ab9e19855001a8d16d",
      "b07d39102a7c42ea8d97a626ab2802be",
      "2cc1b297cb4f43f4b74d8039abf5fd38",
      "39d52b8707eb417b85fbb37c904e10a6",
      "0efb423d18814a798a0d94ff489c1fe2",
      "42895d7bbfcc4ecea84236a4e46f210c",
      "b9d1f5ebc5464096be42094649d82aa6",
      "14169f1ccd874425bf9aa8bf7c8e20c4",
      "0bb335463c664a0e97c3220927101081",
      "0769c47242df4a3380f27add1b0e3118",
      "0262bed0ef024b679198f2fc74680504",
      "4904eee190a54112b693ee4d75e8370e",
      "4b099c3c6f1e40deb8fd8583c296eed6",
      "ee2886be84ce4a33b01bcdb390b5109d",
      "c429bc7a99f348c090d7bf245a4083a7",
      "f8fabb79f87a41dba8b59bfdeda556f3",
      "1d917179c7b64ad6861984fd16298c5c",
      "4a6db7431ba743d0bf4c24a9a4cf597a",
      "f49d0ada76e24fa89b659df498a21498",
      "1051e615683d4d528819af7d7faf22b7",
      "add4dde1908745f580edf8ed57885655",
      "2409cedc96784fcaba8f85c41ab0ed11",
      "4e075df4eab94290b0da70844f5b832a",
      "6d8403cd69834aeca1f5115b2d060a7f",
      "477d4639d01a409086116f8bc4f58fa5",
      "fdc64dc5b02c4b2a93f9da1c85776b7d"
     ]
    },
    "id": "-AEJ-PwpMu_j",
    "outputId": "588f1e28-b40e-4412-93f9-1f8d53f734ff"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
    "from huggingface_hub import login\n",
    "\n",
    "#login(HF_TOKEN)\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMzVLhsM3jvc",
    "outputId": "9582c356-14c3-4644-d2d6-36fb61b2095e"
   },
   "outputs": [],
   "source": [
    "!wget \"https://github.com/awsaf49/flickr-dataset/releases/download/v1.0/flickr8k.zip\"\n",
    "!unzip flickr8k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uR1OA2sk_Fqe",
    "outputId": "ec755e6c-2272-4d59-e870-8eedbe9211d2"
   },
   "outputs": [],
   "source": [
    "!pip install pycocoevalcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1epXVmS-7nF"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.meteor.meteor import Meteor\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "\n",
    "def load_flickr8k_annotations(annotations_path):\n",
    "    with open(annotations_path, 'r') as f:\n",
    "        annotations = f.readlines()[1:101] \n",
    "\n",
    "    references = {}\n",
    "    for line in annotations:\n",
    "        image_path, caption = line.strip().split(',',1)\n",
    "        image_id = image_path.split('.',1)[0] # image id\n",
    "        if image_id not in references:\n",
    "            references[image_id] = []\n",
    "        references[image_id].append(caption)\n",
    "    return references\n",
    "\n",
    "# Annotations yolunu belirt\n",
    "annotations_path = 'captions.txt'\n",
    "captions = load_flickr8k_annotations(annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y56G-q32d_Ay",
    "outputId": "8ef307b1-0021-4706-894b-42ec3e61f446"
   },
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Briefly describe in one sentence...\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": prompt}\n",
    "    ]}\n",
    "]\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "image_path = f'Images/1000268201_693b08cb0e.jpg'\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "inputs = processor(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "output = model.generate(**inputs, max_new_tokens=30, temperature=0.4)\n",
    "\n",
    "generated_text = processor.decode(output[0][inputs[\"input_ids\"][0].shape[0]:-1])\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiJCzSa99FQV"
   },
   "outputs": [],
   "source": [
    "references = {key: value for key, value in captions.items()}\n",
    "\n",
    "generated_descriptions = {}\n",
    "\n",
    "prompt=\"\"\"\n",
    "Briefly describe in one sentence...\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": prompt}\n",
    "    ]}\n",
    "]\n",
    "input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "for key in references.keys():\n",
    "    image_path = f'Images/{key}.jpg'\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    inputs = processor(\n",
    "        image,\n",
    "        input_text,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    output = model.generate(**inputs, max_new_tokens=50, temperature=0.4, top_p=0.8)\n",
    "\n",
    "    generated_text = processor.decode(output[0][inputs[\"input_ids\"][0].shape[0]:-1])\n",
    "    generated_descriptions[key] = []\n",
    "    generated_descriptions[key].append(generated_text)\n",
    "\n",
    "candidates = {key: value for key, value in generated_descriptions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGuf7U4casJr",
    "outputId": "e74b5bce-9568-4190-9f51-515befcd8446"
   },
   "outputs": [],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ks_T8uciQ9pn",
    "outputId": "dd2a3244-fb37-4035-f8d4-66fa8d4139a8"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(references, candidates):\n",
    "\n",
    "    bleu_scorer = Bleu(4)  # BLEU-1, BLEU-2, BLEU-3, BLEU-4\n",
    "    bleu_score, _ = bleu_scorer.compute_score(references, candidates)\n",
    "\n",
    "\n",
    "    cider_scorer = Cider()\n",
    "    cider_score, _ = cider_scorer.compute_score(references, candidates)\n",
    "\n",
    "\n",
    "    meteor_scorer = Meteor()\n",
    "    meteor_score, _ = meteor_scorer.compute_score(references, candidates)\n",
    "\n",
    "\n",
    "    rouge_scorer = Rouge()\n",
    "    rouge_score, _ = rouge_scorer.compute_score(references, candidates)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": bleu_score,\n",
    "        \"CIDEr\": cider_score,\n",
    "        \"METEOR\": meteor_score,\n",
    "        \"ROUGE\": rouge_score\n",
    "    }\n",
    "\n",
    "\n",
    "scores = calculate_metrics(references, candidates)\n",
    "\n",
    "\n",
    "print(f\"BLEU SkorlarÄ±: {scores['BLEU']}\")\n",
    "print(f\"CIDEr Skoru: {scores['CIDEr']}\")\n",
    "print(f\"METEOR Skoru: {scores['METEOR']}\")\n",
    "print(f\"ROUGE Skoru: {scores['ROUGE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjEX2GMPxKyy",
    "outputId": "887004aa-4c8c-44fd-eb6b-71be0e7dabff"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, ViTFeatureExtractor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_id)\n",
    "\n",
    "def load_flickr8k(annotations_path):\n",
    "    with open(annotations_path, 'r') as f:\n",
    "        annotations = f.readlines()[1:]\n",
    "\n",
    "    references = {}\n",
    "    for line in annotations:\n",
    "        image_path, caption = line.strip().split(',',1)\n",
    "        image_id = image_path.split('.',1)[0] # image id\n",
    "        if image_id not in references:\n",
    "            references[image_id] = []\n",
    "        references[image_id].append(caption)\n",
    "    return references\n",
    "\n",
    "\n",
    "image_dir = 'Images'\n",
    "caption_file = 'captions.txt'\n",
    "captions_dict = load_flickr8k(annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkXIVxV846Mi",
    "outputId": "e2d560b2-b241-44b9-8d3e-932688829dc5"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "image_names = list(captions_dict.keys())\n",
    "\n",
    "\n",
    "train_images, test_images = train_test_split(image_names, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train set size: {len(train_images)}\")\n",
    "print(f\"Test set size: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILXaxFEA41GK"
   },
   "outputs": [],
   "source": [
    "class Flickr8kDataset(Dataset):\n",
    "    def __init__(self, image_dir, image_names, captions_dict, tokenizer, feature_extractor, max_length=128):\n",
    "        self.image_dir = image_dir\n",
    "        self.captions_dict = captions_dict\n",
    "        self.tokenizer = tokenizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.image_names = image_names\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name+\".jpg\")\n",
    "\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        pixel_values = self.feature_extractor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "\n",
    "        captions = self.captions_dict[img_name]\n",
    "        inputs = self.tokenizer(captions, padding='max_length', truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            'pixel_values': pixel_values.squeeze(),\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  \n",
    "            'attention_mask': inputs['attention_mask'].squeeze()  \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMF1eq865HBs"
   },
   "outputs": [],
   "source": [
    "train_dataset = Flickr8kDataset(\n",
    "    image_dir=image_dir,\n",
    "    image_names=train_images,\n",
    "    captions_dict=captions_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    feature_extractor=feature_extractor\n",
    ")\n",
    "\n",
    "test_dataset = Flickr8kDataset(\n",
    "    image_dir=image_dir,\n",
    "    image_names=test_images,\n",
    "    captions_dict=captions_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    feature_extractor=feature_extractor\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
