{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owfsMh2wgrhG",
    "outputId": "6bc7fac5-5841-488a-8dff-795aed533fb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trl\n",
      "  Downloading trl-0.11.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deepspeed\n",
      "  Downloading deepspeed-0.15.1.tar.gz (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.4.1+cu121)\n",
      "Collecting datasets (from trl)\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tyro>=0.5.11 (from trl)\n",
      "  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.9.2)\n",
      "Collecting nvidia-ml-py (from deepspeed)\n",
      "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->deepspeed) (2.23.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.4)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.9.1)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (16.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->trl)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.2.2)\n",
      "Collecting xxhash (from datasets->trl)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->trl)\n",
      "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.11.2-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.7/316.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.0.0-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for deepspeed: filename=deepspeed-0.15.1-py3-none-any.whl size=1483862 sha256=56161b8d6ad05b551904026bef3076a1b25c9d7c31ddc0ca305f36d7b748b84b\n",
      "  Stored in directory: /root/.cache/pip/wheels/da/cb/14/9cbba50c73df044eb32a7ca29e34844c5f8959e12d22ae8b60\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: nvidia-ml-py, ninja, hjson, xxhash, shtab, dill, multiprocess, tyro, tokenizers, deepspeed, bitsandbytes, accelerate, transformers, datasets, trl\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.34.2\n",
      "    Uninstalling accelerate-0.34.2:\n",
      "      Successfully uninstalled accelerate-0.34.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.2\n",
      "    Uninstalling transformers-4.44.2:\n",
      "      Successfully uninstalled transformers-4.44.2\n",
      "Successfully installed accelerate-1.0.0 bitsandbytes-0.44.1 datasets-3.0.1 deepspeed-0.15.1 dill-0.3.8 hjson-3.1.0 multiprocess-0.70.16 ninja-1.11.1.1 nvidia-ml-py-12.560.30 shtab-1.7.1 tokenizers-0.20.0 transformers-4.45.2 trl-0.11.2 tyro-0.8.11 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers trl deepspeed pillow accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raXz6py-m7c3",
    "outputId": "392f5a1e-fb50-4268-ef36-c71468dee7c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    SFTConfig,\n",
    "    SFTTrainer\n",
    ")\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761,
     "referenced_widgets": [
      "13df5b36850846cc900681112992bd5b",
      "d1a5be26425e4754be5b5c0b6b04daa6",
      "8f76487c04744cac9cad561ee1d7a1c1",
      "5ff647172ad245b88819c04eaf879739",
      "cb9d9b069f0b4987bd66045fef52457d",
      "365d4f63db85434388bc3353efa2df4f",
      "a8e4c28aebe042f4a9a8c549d637aeb3",
      "d9cc6a10b3ec4b4582d18ea253e7a98e",
      "d9c5e760d65e4683bf076218253cc7ce",
      "90f33936e8b54fb0b85cf608397eab14",
      "75de8090edcf482788589622f64b7295",
      "78f089cc4f304a539fe5794368e031fd",
      "0a45eacbdd484203821cc1d711770ad7",
      "69df02388ff14654b53ba5557e5c10d3",
      "2b2bf1d0cc9240069c7f992c70411e13",
      "738fa5af83fd4bfe86db309720bdae14",
      "a24cbd58e73d45528f5e2563a65ab61f",
      "d049c02c07d441efaa814886b2270978",
      "39ec2596e6ea4a4981771b5e0b2a0fe2",
      "3ba4a5bd104f40b0bfeb3da3b2c7972b",
      "6253fc197e15412db1a02584b4ed64e6",
      "0f734fbf518045f1a6eceb06bec4d84a",
      "507ee3f92ea443879a2474ae40575d06",
      "7d056a715c024405ba2c4bc381a9d947",
      "28ab552403dc405a9962e5a83f4c9dbc",
      "6fcf5017499648af86ba70f9784711ef",
      "cddfb8b800a6418fa81468aead1fd02f",
      "bdab032c11034e11aca202a0c8cd4a43",
      "8ad2ed1947914723b3af2a1b8081456c",
      "66e0ce41a8e24d9ba2420be06c59cd6e",
      "c6a9ba8ca6ef44a4b0d1483d3bd83a07",
      "940dde2b46364f44b6a962c99217cfd1",
      "22f6433bf68e40cc8034a1014311b234",
      "e217dd69af454a068668a90129bbd8d7",
      "02d9e9ddb55243e2a0e65757d75be565",
      "c5a1e4a58979447fbf00bac02ce4b97a",
      "b1b52639ce234b75b36192ef1af166b4",
      "5bc4657e9e894a2f99e5b76619fd1c6a",
      "94e8eceda4024b83ac4c7ae1564c9a9f",
      "9d7439888ac340d08e1f87cf2e6ca093",
      "1f66514f05064d94be01484ff47905f6",
      "34c5b4ecf5384ec9803ae6f7087f9b77",
      "57fb91afe68f4a33bf0919d381224c3c",
      "847ab31f60144dc0bc32547252d04454",
      "cfe9b580b5e1471196f0790ced82a7c4",
      "d7f8672ec71442c6b0271de887934c90",
      "5bde4b21ca0a4ad18a94ec77876de0b9",
      "71f8902f3a6e46cb8f4838142b7ae7cc",
      "09f69193be98481d8485553cf140a1f7",
      "595f039729a7411db4ee84dfda296990",
      "f892eea978ba468984e4fbdf24f0677a",
      "f8a719beb2ec4675a60c105a856a9c0b",
      "e58bb895efa3457f9b4adcbda4885ff7",
      "a77e0310aa77489daf407fb318697c25",
      "e08da830fe8d40549dc72281fe09c63d",
      "d4aa5f0264ce4a9883b738a86ab5584b",
      "6025bb6497ed4f149e06d7274c9812f7",
      "2cfdc2f57f654af7b3f63597cc644146",
      "9778ee2d4d074920b4b3434c20b316f5",
      "a810b1a02e01459e95ca4e26271279d4",
      "753bbdecac5e4d39bd59fa1b58b8d3a3",
      "0075b9ef4bb045ed8c5495311c93be5e",
      "de996b3b1efe4bfba2c7a3005841ae83",
      "6f880bb452ab4bed849b719fec914505",
      "10dc84dc4b0349fa9e33cc27d3ab5d2d",
      "051d53c3cf62458bba9f01aca06d7b1b",
      "b0d6084f51ed4ee593095bff6553ba84",
      "146fb96888dc4e1a9877c212fa82bfcc",
      "2c457b7229874222ad35244d6d3d1253",
      "35cb3564eac04d5c9c4d6fce67ffabee",
      "348fe99196d64636aed944b0e8b9a056",
      "58f47f2135104a4a872e609903618f97",
      "92220d3784ab4bf6bc2c2bec4e0fba76",
      "027eb463c108468a9a699c97ef09a28f",
      "ff158674170346fda8e3291b6789a473",
      "2283ae239140423d9fb2a0feaf1c58b8",
      "9a5ab45df2cc4fa1a702bd9473739702",
      "51ed5fda20d342438058dcb88934bffd",
      "beca81d6bf1e4123a7c6300feaaaed61",
      "02e7ce2c59b1413299e12f487a3c26e1",
      "412f2b1452dc449ead46f68c33c3a6a7",
      "89a3cd3cd3a74bf68922699edebbb35a",
      "9cfe29d8246743298d87fa4f1f2021bb",
      "8a79fca6d2dd416987c0bee31f048a23",
      "348059b72cb64c02891877e913be5cc0",
      "5945b891c40a4567bfa2411b9329e7f8",
      "7afe3446ffed461788be6925c549ddc2",
      "b742da80be0c42e59f05beae233073c6",
      "a88d9e722829477184df6c1e00c5fdac",
      "c81390be00994207bd05c0ce345d7a71",
      "6e3d33b2fb7946c2abe0a9f8e4eaa998",
      "e6685682bd2e4c459badc0e3352f1d22",
      "ed6897c9cf6442d2b9e870c68a83f238",
      "64e6fa6e74f64960a96f63855e81d24f",
      "0f0a735aafac44afbe1fba6c54460fb8",
      "95dad51e629b401a9414ec9387dd6edb",
      "d4a5a1f9973c4da6b206c300c74e6a28",
      "4558ad75854646438fb4c42be4f9751f",
      "750364b223214a5099f815e32cc2e836",
      "10a132d097984c628c1c94fa5f8fc4b6",
      "df843a6e056f4aaea064b8fe1aadabfb",
      "8ebea0dfdc6c446da306984ac8203cd4",
      "be7ac3e44de14ca2b4c88bbd01964e6c",
      "6ab6b6f041064b7f99835fc319d42491",
      "53dc161ef90f4018a1dae8f66563f41d",
      "42eab29c02bd456f8140dcb25c38b378",
      "4273f68299414a13b05dd28780edb708",
      "02955190dff24a3491a4b0c203b7a991",
      "a3f288cfeb3d48cd858bcbfeaa3d0420",
      "49ffde43a03f4cc1ac380980968f5d41",
      "269b35b84da54a6f9f1c54c7daaa2345",
      "62b562fdc62846508c8e92ce38c315d0",
      "7b09fe64bc12450991180cece0025ce4",
      "ddf7b59fcb834cc297c30c785f6c1421",
      "c732fcc575ee4a53b09900fc995e29ed",
      "e40f3431058f4c04bc0672730e6a9e30",
      "89d4d16412cd4e5ca1febd3a015c3747",
      "6423e1164cb14d64a3b564e6d3683124",
      "9a8d20d0af3d44eab357ba2c48946b96",
      "0b6b781c7b2342679ca91959ac73c24e",
      "276bf71e3174486bb67d73cf07be6c01",
      "b073c97a1ca4487bb74ff40d90ac4dd7",
      "71aeda31fdda46cf80943efe162e9d65",
      "c4da0ac7b6814c2480571490814086b4",
      "8b376e7f0cf048efbccfc01a9c961168",
      "4841b4ac9b16451d993317c8c85840f1",
      "f28e06f5461f4c54866614bcbbb82d02",
      "333571ceeda64040b6e21129a113ffeb",
      "b10779c3abe94d1d8d2ae0a61e917459",
      "3c925a869b3940439b74fb93ddffeffc",
      "3a1ae6f8f7074d0cbecf072f37efcbea",
      "5fc0b056262b41818e7aed9e78ac0b0d",
      "a1751c82ed9b4798aabd3bde4ed6367d",
      "51d17c85ee994492b673bf07f4366308",
      "14d2bb5d981645d396664eca7a7afcb8",
      "ad2bfc5eb58147b4b431d1a91373016e",
      "a943b3b0bac04fa28f97f4adce4b72f2",
      "1fbeec15e5b747c9a23bed898cef42e0",
      "55319e1ca3164ab4b95eb645f7e947b7",
      "b93afd91c3464a25978f321033b9a67a",
      "43ea1263319c4e9d913ad9b68577bbaa",
      "bcf9953d99dd476f8cbd5d94ab014d03",
      "b04a9ef65da541478b9912eb579f71f4",
      "d986876be2df430a8dd8186123955f50",
      "2ea17a101e0a4219b4b31cadd3952e53",
      "02fbfbae989b4b77ad95d19f47d51764",
      "4acd61e1071e4969a3b3614025a5f8fb",
      "a3d8bbba5f8f462fa9dfbbc7c307873a",
      "a763ea209d114785b445e3cb873b4e41",
      "db3a13f1739f497c93f4de3192f4aed8",
      "feac8df75c48488587be69fbcfd237e7",
      "3dc41432170042c3b7c713ebf90c0c36",
      "b3c31e5184f94b3a91452ced7aa6eeab",
      "06909a0024a54220ac450400612e36ea",
      "8db1fc01ac2d458b83ce524159ba7e74",
      "d20d4d42242a44a693933747a6b86b68",
      "41705deea0d846bdb2afa210edd6eb58",
      "2bc3f70067b742a9b9796ee877521d52",
      "fa022868d14340cf827d9b2ed9161421",
      "1b7233dfdc054279903a70967be26e40",
      "bc8e47622147413f8ffcf692dea5f97f",
      "a75180ed892b4cc686c676aca16bc7d7",
      "3c1e0b0a904a407e9f052ca39d247a1c",
      "44a9728dc0a14f1baad1c1bbc64e9b0c",
      "0fbf530e3d2945df90e09b3987bac35e"
     ]
    },
    "id": "iiMbxaPSHL7Z",
    "outputId": "a7feed31-55db-4c9b-bd1f-1b6148e3a61b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13df5b36850846cc900681112992bd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f089cc4f304a539fe5794368e031fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507ee3f92ea443879a2474ae40575d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/5.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e217dd69af454a068668a90129bbd8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe9b580b5e1471196f0790ced82a7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4aa5f0264ce4a9883b738a86ab5584b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/5.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d6084f51ed4ee593095bff6553ba84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/89.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ed5fda20d342438058dcb88934bffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88d9e722829477184df6c1e00c5fdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a132d097984c628c1c94fa5f8fc4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269b35b84da54a6f9f1c54c7daaa2345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b073c97a1ca4487bb74ff40d90ac4dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1751c82ed9b4798aabd3bde4ed6367d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d986876be2df430a8dd8186123955f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db1fc01ac2d458b83ce524159ba7e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForVision2Seq.from_pretrained(model_id, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJzeF-CKG6S0"
   },
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    texts = [processor.apply_chat_template(example[\"messages\"], tokenize=False) for example in examples]\n",
    "    images = [example[\"images\"] for example in examples]\n",
    "    if isinstance(model, LlavaForConditionalGeneration):\n",
    "        images = [image[0] for image in images]\n",
    "\n",
    "    batch = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100  \n",
    "    image_token_id = processor.tokenizer.convert_tokens_to_ids(processor.image_token)\n",
    "    labels[labels == image_token_id] = -100\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945,
     "referenced_widgets": [
      "8c7bb3409a9444148e3a6b73ca467f97",
      "eb5cddab517744b7b417a8a2ebb928b0",
      "82b1f6874ea24c37b7b6ef77a3adafe1",
      "05802b24f6c641cb9d2f879077c4aebd",
      "b9f0c072010448e98db80206ea7eede8",
      "24a99745ce054bae82d27d0187c93463",
      "45101c554f5e47289f8192b4cff9fa1b",
      "dbe3f6cc93544d83a810e5b90bf9a9bb",
      "e76daa022a394382a2f6b1888ea7e204",
      "b4ee4f99e00949b6abd455f46a0345d9",
      "359fccc0126a4f3abcfb8170f85f0f82",
      "f73f1a46af7a4a17bcf2ad96cac85495",
      "b4cda77a637a4dc488a17c40fda06d56",
      "6e026ee138d948b4ad397ddc7c035c61",
      "3e47202beb72416ea9dc8ec5b76e54a3",
      "945fd8f5bdd748ac937222f56e525953",
      "3066b49516614d09a1ef71519ee655a8",
      "b48469a7d5a043568fe36e4b75d8cc1a",
      "7bd91b995d1e4a2eb4bd2d7cbd293c48",
      "39702a0992734d45a0f77cb496ef0e7d",
      "0b53aa8c5a404d84b9a512f626c11b65",
      "26d446a497af44869c6f188401f35c76",
      "41d00c3edbaf4c1cb106ec16bc24614f",
      "b4bd058611f147f9adcda6133cf6f72c",
      "18ea3ca853694966bff2abc3af5b2014",
      "fa5ebcc07ec64d97982e5c5bfe7f2d40",
      "5c55b7ed2af84a14a8de2b83daf13ed5",
      "6f0ee6acc3214fa4a12eaf153191d5cb",
      "a19edc84f8b7460f8b1296d9adc99d2a",
      "09e1af1052744f1f845dc9ffae0f60d6",
      "6f2b8d766d5841068563c693ffcf48ee",
      "8ddf0e25a51d4614b83280cb2ec3e00e",
      "647845cbbea94d6cb83ed1ef66523b73",
      "02e520bead944abea9b0694794710946",
      "6309c522631d41d18f0079ab05f7e5d2",
      "626577a920814e21b342e561554947a0",
      "ea6eb368fca646ef90fb1b995527460a",
      "e9d613a495784695a6a82692489e274e",
      "13e979dfd6034913b2fbd8adf2b5b9fe",
      "b246cbf4da2b49ba85250bb53aff347a",
      "c7c3bbf7987f4f519ddcddd30fca45ba",
      "28c98d7041c04d65a371c66204e3b6d4",
      "6cff3bf07e024c76bbc2b04dae790dde",
      "b9438926dd4745f19087631383d65fee",
      "290943e075084e5b98db2116a0692772",
      "4c3bbb47a5b04e8d8287d52c899e8679",
      "7c0bd019dc6d479d9256e27d11e38fe6",
      "10377fd17be74c80a8dffb0fbc850cf8",
      "f7ea8e22872d4e4c8f3e7bf6e5eb308c",
      "4c4dff112f0f4eb48e1deec4b31d1160",
      "149a1bfed5d0428999d49d93d73fea00",
      "de418d176f7248afac14ca701da3ccca",
      "2d80af7939b745a6b251e39f89924fc3",
      "243d5fd0ec254a57a9a8b10ba93e2246",
      "839dc1330a6e48cd93b286003aa85dd0",
      "ff93a61d52e64d03acbdf19e59d484b7",
      "6fe3ac35cc4543549d73ad7d1db80d0a",
      "9879adc204b049719ee0ee01915dec2e",
      "2817a466718e4489afb30c5b77551499",
      "ea2b7e9f30754af9a186381846431922",
      "2afac3a4b17e415aa3dcce8d3a249690",
      "ea1352663ea5420cb2002f8f6e2247b3",
      "f9506fd6e49440878ea0c90678aa44a4",
      "889f8981f1b6474f983cb27473188044",
      "7830721c58b8421583198a32727e2f9b",
      "15c1c61e2f0b4d559e9f58166ed91314",
      "26f645eb4d994d43b4922222065a3567",
      "d02877badff2400083feda0ca9569593",
      "218e48319996407c9f35141b10d35f20",
      "82b84d01d0614f6188fe342fe13cfb80",
      "00a04744f2974b1ab068acf5c17db4bb",
      "7de41b1bdcf94be9b8753876b51f3f12",
      "7cc6aa5a05934c6ba6b42ac0a04bfa7e",
      "1e6efbb58f664a2aac5f4b36cc8d0b38",
      "8ec026444229480ba15dc9264708ef98",
      "10a43a05e4bc4e738b41ea1a5b73b90d",
      "86a1f52839ad477da542cff32b3743e9",
      "3dcd9c15129247888d07720ba06ad820",
      "fd8fe95912f44bcc868fe1d6e80e0880",
      "c33b2af8870c4162812809c33f367ebf",
      "a9c9b9b1436b4ef48b90bb91e5e3939b",
      "200ed0663b444241be742f94d748db12",
      "eaa1be4bce624bf996cd8057292a3cc0",
      "f856400ddb464af08f3e64253040d614",
      "eaaa288b71a14029baea56400a37f85a",
      "619976c77f2e436eb0cd7248ce93b2c1",
      "095959f6f2dd4ccb9fe241baf5a81c61",
      "2b6f833b5b0740f28bd4d5bbb059be26",
      "0a2005536de94a66930c69d907d8443a",
      "95a1daa70c7d4929949f6b7de1e7f8c8",
      "6fc2c83f930b47e3b5fe4f20e49fd6da",
      "f01deb93d28341b29a12818038259cc9",
      "ac79ee01ace0439e9006f35d4c913a36",
      "9b2af301585f4f909097643266e0c125",
      "d1ff55bbf45c419d9f13c8660ff56425",
      "0f5ff24e300c4986aa0fab8c01bd3dff",
      "71ade230cfde44b295fb68883a936ed2",
      "b6bc51d54a36496aadc1c2d6d8d1387b",
      "acb4f4b6c9854ead807d4ef7291599b1",
      "286ececca7d04d43b98c611c3ccb1b61",
      "dce543c8958347ad9a640cb9d4fa4159",
      "5fe7d0489f5a49c3a67e8a2e779c2c28",
      "7ff2b7d94cb74310b343344db231919e",
      "5c77d8bd824f4c7daa1cdbc53bcfb091",
      "aaac3da9c3ef41db9c8c04e6fb136654",
      "9c78a1488c2f43479d0c7ec557b204a3",
      "1937b3a10e1a4f7f897d8e9080a6c61f",
      "77cfc7405ef74c5081a883b2a49fe9be",
      "e73037ddd612410cae1394efc7530a2d",
      "e30ee24175a344478fc8902b37cad1a2",
      "b857ba28d07a42b6ba6a82ddc980908e",
      "caaf6b6fc9154def99a5bafee01e919b",
      "32283c593a244b9d8c751fd6d84f38ca",
      "b9db1715b9b841c28d15018dcc89fa51",
      "35c60aa571d34c1ba6cac214a731a3ee",
      "12242172f12b46438997c5c3c2aa8f26",
      "9536e0e0fc804455acef0a56aeaa7d3b",
      "e38e2a8672a34f12afaa7649a074bbd8",
      "88d8d5fa158c4af49d5bfb70d8609789",
      "9144d9999ab44051883c71f6379ce909",
      "a4b8694c79164febaf6d3bfa9074a0ae",
      "cf0a8c8eab0e447b8d2c803d62309b94",
      "efe8a3febce642ad9b975dfd712eafa2",
      "c4f7de0eb8964351b5db2aefbad61fe9",
      "2c57c6c758e84f68b3f70690768ad275",
      "58d6f54852d94493b02f2962860daaf1",
      "4994d41d31064b36ac7ec73eedbef0f3",
      "7f436319138f4c9890e1aa6cbd760385",
      "0633ee5dd71b4ee89200df8b78fb4115",
      "ee713e9aabbd489d8dbb9f3a09da5f93",
      "a682215c58734d5588651bb1018007ac",
      "c39074c53d0049d99673c2ab20ce9cd6",
      "6f62a13f305e4de59be0e321b5e767df",
      "bd41f69431954b61b75c390ea74b323d",
      "148a04fffeda49e8a9aa1b1dfb67adea",
      "33e3173fd1c64028abd9c005d8e81491",
      "3e63207da8244c67b16366457cfb8af6",
      "517fb88510844eeea5516e9e0225a609",
      "12191076f6e84053ad438ad0e0af3ce8",
      "17bcbcbe4f044626ae122d7e560eea27",
      "0104bbebdd1d455cae50a6eb63557182",
      "87c1108f9dcb4d848d361cdb2edcabe9",
      "b6e5fafa82a34fc3b1b124ad59b6eafd",
      "d2677df934ca4ae6ae88d7ef8d8c4ad6",
      "3c491f56b8cf4abdbc874d7a46b11bc4",
      "271fc4b48d09442285448b1a15b28d1b",
      "5e80fb83e01a4591b72bd550947cd22a",
      "c0da42cf7cbc4e67b922947affe00c41",
      "0f87c11687b2435baabb27f49771416f",
      "e20c585956534658909ef3ed10a662b6",
      "4c4feda4c328470c8f8952f2499a48d2",
      "bb0cae96e1704e2597550f7b4cba804b",
      "e22fb6e7437043c990a669033e01b316",
      "ad4e98b3700d4badb705e75c3f31fa68",
      "7805efa902f446d4ae4a4b62b86feea6",
      "00cc979299354990805305a959a98d5c",
      "0cf84ad483ad491f89b3f406d0418d24",
      "fd500aa6194c4bf0a9e2f48680f11d22",
      "3425dc6d74a949d2ad78d1545ccc1687",
      "f4aa2b978ac14703b7b63faa155b2fbb",
      "04d156be65234f1599fea412314996dd",
      "2ea42bf147be415684f07256f8d19efa",
      "5d045d25001e4fcd89e954138e041bd1",
      "4f1301f86407433095f620bb2083bf0e",
      "feb3770b6664428bbe7fa582a9eb4b73",
      "998c73946b094df3ade29df898b8d81d",
      "58365aba43df415494c05efe48a4734d",
      "9f88e938e5554fd587718f808863af8c",
      "7616a1e02d6e499194490ecde9fb07dd",
      "9cd54cf4c430455f85afc9b8048580f4",
      "e509601a3cf34a9bae0beb21716bd3ae",
      "1a16e9a8276c476fa3d32acf5443d49e",
      "c474995ded69439b9bbd3945fc16269e",
      "ee2d0800f1424fa993d00d935c2f6e27",
      "95d88dfaa31b406fa89882897b618d32",
      "70196f4691594a968df55d01e10fa2f9",
      "cbddfdee88224b938035eff69f1b387f",
      "17900a76cac1419f8eadfb5210312409",
      "d8680e6c6284499596c6fec5463b6d58",
      "ec6ea0beefd544e7aed6fa315e000b2f",
      "6e33f8c1fb884448b47060b6c5cf67c8",
      "fad224d5c2b148a795763fa8cad5c3a0",
      "b0924171591648c8be96f43afb73ae7a",
      "c0960a00b67f4266826a4fe57b5ee01e",
      "17b977c6aa084e2387647dfb5d8642f8",
      "3d6a2f591d744101a345ba272031f074",
      "4920774bb7804692be0e6e050a83fdef",
      "59ec6c284a08405fbb2027e4fbe4f13e",
      "2fa2c44de21a4bef832d365c6fe1ee74",
      "a2cc4f43056f45ee95617d62b007a536",
      "f1c58247f66144f3b8c69f509f2ff1a5",
      "c3996094e5e44e8bbcabee003729dac8",
      "0cf80d6ca3d84050a70602b08cfcf081",
      "f6e662cebf00461ab488d8dab9ff0445",
      "826ba10825d4438b95fee1dd9236c927",
      "07b6bae1ebc34f8bbf473119de63d974",
      "ae9490576aec44dc9741071a8b537003",
      "651ae9a302b745b4879f78f7ce3f8de4",
      "df1cf8fe1c044c879084c423524bd552",
      "8972724d8a0943e8b58c13bbcbec43cb",
      "1db72e2612154531aad47598337a286b",
      "ae2afcd5b4d3470b8c0044d5b9b0e584",
      "5d52c428e5f0473b95871b76b37135da",
      "6b7e4a34db6245a098de312b12af54bf",
      "be3c725aaa334fb88d11ea23c6d1d226",
      "9b324eb766f24b4a9f476e2f3f7be7b7",
      "5bd0af6f9c8b4c7e858375d3707ce188",
      "d7cbf1558a9d43c2b45750a5e7e9b457",
      "de5565988a2340bba130d7945b13d824",
      "54485a74863e422e9fe5550a14e1a118",
      "28e96f8916474d419a663672b5f282fa",
      "c932988af46b4e96836b691a944b5cb8",
      "429593201efd470a9a15f02a2c3165e1",
      "7f7d6eec2291411192e4c872a58bfd57",
      "a277fcb2ed4b423294160a4ec744a0ef",
      "d9fdca56195048fcaba0d1710ee359c4",
      "a7d805d8fa4041a8b2f9d9d0de02f09f",
      "f30f47402ba440cd96fea315f81118ac",
      "8524fa0ae0ff49b98881a9057f758b19",
      "04a23cef74b84d6d8ea978a94a389dc1",
      "af09997b913342009e955ce7831c47af",
      "ac054646aae1484480649d32c64a8a03",
      "5a8449abd56349f7b82d52bab474ce7c",
      "ddd6619ba94b41abbff5642019ecfdbb",
      "696178ed83234af48e03276afd2c164b",
      "7c219ada01584da6916fe9d64e1d2ff9",
      "50498886bc2b490bb5b14ee972941e0c",
      "760885de352141ec8e86b170c0eb781b",
      "1bc1d67849fe4acb83c1abdd54eccdaf",
      "62af80ccf4394722bc2e9c607ae35809",
      "60efb9641aff4341b1ef8fed1a53ac01",
      "090fc793446746d7b83e58c31049dca8",
      "5a4c90eaeba94de8a808111d31494362",
      "637bdd79f1d844e193b3ed2cd8b58d30",
      "9de1c907201c4560b60ccbba654ef4a4",
      "f53a7711829b45c5b7b0ff2cf859ddab",
      "1a7fa69070f64e8cb5dc0a385139f43d",
      "677b80b6de004b3c9d598a971f20ad1f",
      "399ba5dd4a3046df8c92ea48ae76767a",
      "8be0586e22444333bbc2ef67eba1b127",
      "032e9d890bbf4858af23c9423a8daa53",
      "03ff9d57834b441fb7475513e9c24bc1",
      "35fc455318ac48dc8b4a8379af44e6e3",
      "203dac34da974fcda96e815879a59ab4",
      "1a20e88abc9e48f693bc806be75a7503",
      "d6d416c087914037ac474b858a3d49be",
      "00c5799a415840c592e9792df87177c5",
      "11998028246f43829c28a97e59d70632",
      "ec7aad6372ae42229858c1af9e041151",
      "0866c96d7a1d462389b97acb3d0ca078",
      "6a4afc9a21b442d98e18419badf8f852",
      "b91be50a4739413bb710d24ed7dd363a",
      "08deb1bc722c40c0a197d58eb4c8a086",
      "9d375f6846994492a14e2776b8233f02",
      "f4ebeca22b14423b8b9799f02c755601",
      "474f91a97a4a4ca68106a9ff7baed9f1",
      "c2d840101aa447549108f4bc012f7ede",
      "c35302d8d713451c96efdfe04490083f",
      "920fb1a7a92843388643d9b1d8ed5b64",
      "bd367c3e828542e7904b087dc4986dcd",
      "b63af5a36cf6425c96ac70175a4849db",
      "9c0d032dd60f4209a901ea9dd5878498",
      "39a78cb3fe264505955307930cd6b655",
      "ae923cebe2d2428c9b8c9dd197a23783",
      "1aa3a71e515b482f9c00115e0e37cf4f",
      "623e0176c7d54b2ab19d284cd7328602",
      "4084faa202254c7c9c33fd5d13fddf31",
      "6086b36a84fe4e9ca8d59927397a1057",
      "3d6aa3c26fe64629a672a06e6f1ef277",
      "f3acacb976d043c4a81a22cda073e411",
      "253891f66f6641f7a17020e655d7d064",
      "e047aa4e7bbd4008babf1fd671a077dc",
      "0282052b189f4c7ba06d609e5e0a95cf",
      "0836b1c6132144fd93f8a712dc705a76",
      "d6f91f7ae612487d89ea4a55293251bd",
      "29d0cc4691d64894b1193f468f472ec7",
      "4cf5402874c74932a8e920a71a39367d",
      "f4fc1573a0804c5ab5beb6e920e3ad98",
      "56a9b74434864feeb64132feebcfa486",
      "12a0e32ae042478494113cc667a6e175",
      "9fdd377e845c4b6f9f27d52561bb4f00",
      "76aeafd03c0240ceb1f342418523c5aa",
      "9e7866420d9943d9a0f48f83fd9269db",
      "5c3792c04110428aae11280a2fd48fc3",
      "1380c1e8a29544edb84f3e03d235eb17",
      "4476ece2d5384d099ac0929fac4ea105",
      "8161ed76def74e5b987869c7ab93b140",
      "51e68c9c389c46feb945f671e68695af",
      "b7ae5208f9e34afb94a2e0408b880f35",
      "3f03f463df774fe3b1ef959ad8d9e570",
      "75733ec4645d4201aee23fd9fa17d94d",
      "12c733f11efd410ebf61ea981c34cd5f",
      "baf5066c86db46f0adf20d1abccd20c0",
      "fd8f475abf0b4a03bf1962af52a0f9a3",
      "f832386e4a594deeb11b2231e0128090",
      "f97f4b75d2da4fe8808b10ffa07e4b6f",
      "a5a0a45a40bf42ba81ea449e22605d6f",
      "8835fa5fafaf4391830806e899c549c0",
      "de939e28c5fb4d2fadb4964498e1adf9",
      "720d9b93880c4086b76e6f568d200e64",
      "788e92d7ed174a4e8b38ba4e79a17954",
      "045b548a56ca4f7b848ad0d2dfe240d9",
      "90a25a3c41b948debdd9fcb2c02e1739",
      "7ce73453475449bf90fc99a8e88ad61a",
      "2ddf5cd102854c198f65d26ccdc5a2a3",
      "f22ef005243d4f90ada23ab96a5cc16f",
      "76aebf1414a9405f86bdec3c79acbbf9",
      "bdec38a513ef49b7b302210ee2d29988",
      "82fb5410b83e4dd0aa507831820f68c0",
      "1723431df4dd44728621da4f8a5531fe",
      "21d50ccd1a494f8c9e966d8a5fca1d54",
      "5363668779cc4d6298461fd3a339e828",
      "f236e9b45f6c46ceb3aaa473da1dd92b",
      "6ad1880b02444bcea0b3adae548eceb2",
      "8e4d3e5faaf54cc5a41f1d3475d19307",
      "17d0f2218033446cbd92a692d72aa54b",
      "c8653ed69fcd44edae586ec69a3b8c30",
      "eace564663c34a93880b180e8a257cb2",
      "8b744f2c039d4604b636ff02b90f0bfa"
     ]
    },
    "id": "u--jvQKOHF5p",
    "outputId": "9334caac-b85c-4764-a28a-90e63a4fdfe0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7bb3409a9444148e3a6b73ca467f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/868 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73f1a46af7a4a17bcf2ad96cac85495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d00c3edbaf4c1cb106ec16bc24614f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e520bead944abea9b0694794710946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/20 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290943e075084e5b98db2116a0692772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00020.parquet:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff93a61d52e64d03acbdf19e59d484b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00020.parquet:   0%|          | 0.00/547M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f645eb4d994d43b4922222065a3567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00020.parquet:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcd9c15129247888d07720ba06ad820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00020.parquet:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2005536de94a66930c69d907d8443a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00020.parquet:   0%|          | 0.00/541M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286ececca7d04d43b98c611c3ccb1b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00020.parquet:   0%|          | 0.00/541M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b857ba28d07a42b6ba6a82ddc980908e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00020.parquet:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0a8c8eab0e447b8d2c803d62309b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00020.parquet:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f62a13f305e4de59be0e321b5e767df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00008-of-00020.parquet:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2677df934ca4ae6ae88d7ef8d8c4ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00009-of-00020.parquet:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7805efa902f446d4ae4a4b62b86feea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00010-of-00020.parquet:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998c73946b094df3ade29df898b8d81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00011-of-00020.parquet:   0%|          | 0.00/544M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbddfdee88224b938035eff69f1b387f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00012-of-00020.parquet:   0%|          | 0.00/549M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ec6c284a08405fbb2027e4fbe4f13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00013-of-00020.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1cf8fe1c044c879084c423524bd552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00014-of-00020.parquet:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54485a74863e422e9fe5550a14e1a118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00015-of-00020.parquet:   0%|          | 0.00/547M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af09997b913342009e955ce7831c47af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00016-of-00020.parquet:   0%|          | 0.00/541M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090fc793446746d7b83e58c31049dca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00017-of-00020.parquet:   0%|          | 0.00/541M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fc455318ac48dc8b4a8379af44e6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00018-of-00020.parquet:   0%|          | 0.00/547M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d375f6846994492a14e2776b8233f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00019-of-00020.parquet:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa3a71e515b482f9c00115e0e37cf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00002.parquet:   0%|          | 0.00/285M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d0cc4691d64894b1193f468f472ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00001-of-00002.parquet:   0%|          | 0.00/284M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8161ed76def74e5b987869c7ab93b140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/259155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8835fa5fafaf4391830806e899c549c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/13640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fb5410b83e4dd0aa507831820f68c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"HuggingFaceH4/llava-instruct-mix-vsft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cp0PjrCuHHvp",
    "outputId": "ab758148-7fac-42e6-9d17-e5e0ff62545f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = SFTConfig(\n",
    "    output_dir=\"my-awesome-llama\",\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_accumulation_steps=8,\n",
    "    bf16=True,\n",
    "    remove_unused_columns=False,\n",
    "    dataset_kwargs={'skip_prepare_dataset': True},\n",
    "\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=processor.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "k0Iq7RJ_HS8s",
    "outputId": "d2f8f315-6318-4d0d-ae91-7ae0413807e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-08 13:45:42,736] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 8.10 GiB. GPU 0 has a total capacity of 39.56 GiB of which 6.99 GiB is free. Process 45933 has 32.57 GiB memory in use. Of the allocated memory 31.47 GiB is allocated by PyTorch, and 620.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d0e4e293c94a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save and push to hub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trl_activate_neftune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# After training we make sure to retrieve back the original forward pass method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2052\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2053\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m                 if (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3531\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3532\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3533\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3534\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mllama/modeling_mllama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, pixel_values, aspect_ratio_mask, aspect_ratio_ids, attention_mask, cross_attention_mask, cross_attention_states, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   2160\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`aspect_ratio_ids` must be provided if `pixel_values` is provided\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m             \u001b[0;31m# get vision tokens from vision model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m             vision_outputs = self.vision_model(\n\u001b[0m\u001b[1;32m   2163\u001b[0m                 \u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m                 \u001b[0maspect_ratio_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect_ratio_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mllama/modeling_mllama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, aspect_ratio_ids, aspect_ratio_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[0;31m# Collect intermediate layer outputs from encoder output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0mall_intermediate_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m         \u001b[0mintermediate_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_intermediate_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m         \u001b[0mintermediate_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintermediate_hidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_layers_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 8.10 GiB. GPU 0 has a total capacity of 39.56 GiB of which 6.99 GiB is free. Process 45933 has 32.57 GiB memory in use. Of the allocated memory 31.47 GiB is allocated by PyTorch, and 620.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "trainer.save_model(training_args.output_dir)\n",
    "if training_args.push_to_hub:\n",
    "    trainer.push_to_hub()\n",
    "    if trainer.accelerator.is_main_process:\n",
    "        processor.push_to_hub(training_args.hub_model_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
